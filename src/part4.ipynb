{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSubmission(preds):\n",
    "    new_index = np.arange(16384,32769,1)\n",
    "    id_col = pd.DataFrame(new_index, columns=['id'], dtype='int32')\n",
    "    y_hat = pd.DataFrame(preds, columns=['Y'])\n",
    "    frames = [id_col, y_hat]\n",
    "    pred = pd.concat(frames, axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "garbage = ['F25', 'F26', 'F27']\n",
    "data.drop(garbage, axis=1, inplace=True)\n",
    "dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "data.drop(dups, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data.drop('Y', axis=1), label=data.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [6, 7, 8, 9, 10]\n",
    "bsts = []\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    param = {'max_depth':depths[i], 'eta':0.7, 'gamma':0.8, 'silent':1, \n",
    "             'objective':'binary:logistic', 'early_stopping_rounds':5}\n",
    "    num_round = 500\n",
    "    bsts.append(xgb.train(param, dtrain, num_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bsts)):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "    dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "    test.drop(dups, axis=1, inplace=True)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    pred = makeSubmission(bsts[i].predict(dtest))\n",
    "    filename = 'xgboost_pred_depth_' + str(depths[i])\n",
    "    pred.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those all improved my scores. Lets do the same thing with the log of the data. We are also going to lower eta, increase the number of rounds, and remove early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "garbage = ['F25', 'F26', 'F27']\n",
    "data.drop(garbage, axis=1, inplace=True)\n",
    "dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "data.drop(dups, axis=1, inplace=True)\n",
    "features = np.log(data.iloc[:,1:] + 1)\n",
    "labels = data.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(features, label=labels)\n",
    "depths = [6, 7, 8, 9, 10]\n",
    "bsts = []\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    param = {'max_depth':depths[i], 'eta':0.2, 'gamma':0.8, 'silent':1, \n",
    "             'objective':'binary:logistic'}\n",
    "    num_round = 700\n",
    "    bsts.append(xgb.train(param, dtrain, num_round))\n",
    "    \n",
    "for i in range(len(bsts)):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "    dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "    test.drop(dups, axis=1, inplace=True)\n",
    "    test = np.log(test + 1)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    pred = makeSubmission(bsts[i].predict(dtest))\n",
    "    filename = 'xgboost_pred_depth_' + str(depths[i]) + 'logdata'\n",
    "    pred.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those did better, lets do it again, more depth and higher gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "garbage = ['F25', 'F26', 'F27']\n",
    "data.drop(garbage, axis=1, inplace=True)\n",
    "dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "data.drop(dups, axis=1, inplace=True)\n",
    "features = np.log(data.iloc[:,1:] + 1)\n",
    "labels = data.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(features, label=labels)\n",
    "depths = [9, 10, 11, 12, 13]\n",
    "bsts = []\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    param = {'max_depth':depths[i], 'eta':0.2, 'gamma':2, 'silent':1, \n",
    "             'objective':'binary:logistic'}\n",
    "    num_round = 700\n",
    "    bsts.append(xgb.train(param, dtrain, num_round))\n",
    "    \n",
    "for i in range(len(bsts)):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "    dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "    test.drop(dups, axis=1, inplace=True)\n",
    "    test = np.log(test + 1)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    pred = makeSubmission(bsts[i].predict(dtest))\n",
    "    filename = 'xgboost_pred_depth_' + str(depths[i]) + '_logdata_highergamma' \n",
    "    pred.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those scored a little bit higher. The highest had depth 12. Lets raise gamma again, and go one level deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "garbage = ['F25', 'F26', 'F27']\n",
    "data.drop(garbage, axis=1, inplace=True)\n",
    "dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "data.drop(dups, axis=1, inplace=True)\n",
    "features = np.log(data.iloc[:,1:] + 1)\n",
    "labels = data.Y\n",
    "dtrain = xgb.DMatrix(features, label=labels)\n",
    "depths = [10, 11, 12, 13, 14]\n",
    "bsts = []\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    param = {'max_depth':depths[i], 'eta':0.2, 'gamma':3, 'silent':1, \n",
    "             'objective':'binary:logistic'}\n",
    "    num_round = 800\n",
    "    bsts.append(xgb.train(param, dtrain, num_round))\n",
    "    \n",
    "for i in range(len(bsts)):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "    dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "    test.drop(dups, axis=1, inplace=True)\n",
    "    test = np.log(test + 1)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    pred = makeSubmission(bsts[i].predict(dtest))\n",
    "    filename = 'xgboost_pred_depth_' + str(depths[i]) + '_logdata_highergamma_again' \n",
    "    pred.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores went back down a little bit. Lets lower gamma, eta, and rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop(['id'], axis=1, inplace=True)\n",
    "garbage = ['F25', 'F26', 'F27']\n",
    "data.drop(garbage, axis=1, inplace=True)\n",
    "dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "data.drop(dups, axis=1, inplace=True)\n",
    "features = np.log(data.iloc[:,1:] + 1)\n",
    "labels = data.Y\n",
    "dtrain = xgb.DMatrix(features, label=labels)\n",
    "depths = [10, 11, 12, 13, 14]\n",
    "bsts = []\n",
    "\n",
    "for i in range(len(depths)):\n",
    "    param = {'max_depth':depths[i], 'eta':0.1, 'gamma':1.8, 'silent':1, \n",
    "             'objective':'binary:logistic'}\n",
    "    num_round = 600\n",
    "    bsts.append(xgb.train(param, dtrain, num_round))\n",
    "    \n",
    "for i in range(len(bsts)):\n",
    "    test = pd.read_csv('test.csv')\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "    dups = ['F12', 'F13', 'F17', 'F22', 'F24']\n",
    "    test.drop(dups, axis=1, inplace=True)\n",
    "    test = np.log(test + 1)\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    pred = makeSubmission(bsts[i].predict(dtest))\n",
    "    filename = 'xgboost_pred_depth_' + str(depths[i]) + '_logdata_lowergamma' \n",
    "    pred.to_csv(filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raise rounds again?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
